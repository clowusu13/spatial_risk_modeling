{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d936ad0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da105867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define relative paths to data files\n",
    "ROOT = Path(\"..\")\n",
    "WELLS_PATH = ROOT / \"data\" / \"raw\" / \"wells.csv\"\n",
    "\n",
    "WELLS_PATH.exists(), WELLS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8984afc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load wells data and display its shape and columns\n",
    "wells = pd.read_csv(WELLS_PATH)\n",
    "wells.shape, wells.columns.tolist()\n",
    "#wells.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c070e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample data for testing when building the pipeline\n",
    "USE_SAMPLE = False\n",
    "SAMPLE_N = 20\n",
    "\n",
    "if USE_SAMPLE:\n",
    "    wells = wells.sample(SAMPLE_N, random_state=42).copy()\n",
    "    wells.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c621e398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at the data\n",
    "wells.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e3876a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missingness and class balance \n",
    "wells.isna().mean().sort_values(ascending=False).head(20)\n",
    "wells[\"ArsenicCat\"].value_counts(dropna=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123212b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets do a schema check see what columns we have\n",
    "REQUIRED = [\n",
    "    \"DataID\",\n",
    "    \"xCoord\", \"yCoord\",\n",
    "    \"pH\",\n",
    "    \"ActcualDepth\", \"Depth_IDW\", \"DepthType\",\n",
    "    \"GelogicUnit\",\n",
    "    \"ArsenicCat\", \"ArsenicCat2\", \"ArsenicOld\",\n",
    "    \"WellDepth\",\n",
    "]\n",
    "[c for c in REQUIRED if c not in wells.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45190930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the pH value, treat 0 and out of range values as missing\n",
    "wells[\"pH\"] = pd.to_numeric(wells[\"pH\"], errors=\"coerce\")\n",
    "wells.loc[(wells[\"pH\"] <= 0) | (wells[\"pH\"] > 14), \"pH\"] = np.nan\n",
    "wells[\"pH\"].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398ae715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# well depth - use actual measured depth, if unavailable use the interpolated depth from inverse distance weighting (IDW)\n",
    "wells[\"ActcualDepth\"] = pd.to_numeric(wells[\"ActcualDepth\"], errors=\"coerce\")\n",
    "wells[\"Depth_IDW\"] = pd.to_numeric(wells[\"Depth_IDW\"], errors=\"coerce\")\n",
    "wells[\"WellDepth\"] = pd.to_numeric(wells[\"WellDepth\"], errors=\"coerce\")\n",
    "\n",
    "wells[\"depth_value\"] = wells[\"ActcualDepth\"]\n",
    "wells.loc[wells[\"depth_value\"].isna(), \"depth_value\"] = wells.loc[wells[\"depth_value\"].isna(), \"Depth_IDW\"]\n",
    "wells.loc[wells[\"depth_value\"].isna(), \"depth_value\"] = wells.loc[wells[\"depth_value\"].isna(), \"WellDepth\"]\n",
    "\n",
    "wells[\"depth_value\"].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca4c9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a value to help with exploratory plots\n",
    "def parse_arsenic_value(v):\n",
    "    if pd.isna(v):\n",
    "        return np.nan\n",
    "    s = str(v).strip().replace(\",\", \"\")\n",
    "    if s.startswith(\"<\"):\n",
    "        s = s[1:].strip()\n",
    "    try:\n",
    "        return float(s)\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "wells[\"arsenic_value\"] = wells[\"ArsenicOld\"].apply(parse_arsenic_value)\n",
    "wells[[\"ArsenicOld\", \"arsenic_value\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78c7bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a binary target used in modeling.\n",
    "wells[\"y\"] = pd.to_numeric(wells[\"ArsenicCat\"], errors=\"coerce\").astype(\"Int64\")\n",
    "wells[\"y\"].value_counts(dropna=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1276d4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rule for dealing with dups - for each location keep the highest arsenic measurement\n",
    "wells[\"xCoord\"] = pd.to_numeric(wells[\"xCoord\"], errors=\"coerce\")\n",
    "wells[\"yCoord\"] = pd.to_numeric(wells[\"yCoord\"], errors=\"coerce\")\n",
    "\n",
    "wells[\"loc_key\"] = wells[\"xCoord\"].round(6).astype(str) + \"_\" + wells[\"yCoord\"].round(6).astype(str)\n",
    "wells[\"_ars_sort\"] = wells[\"arsenic_value\"].fillna(-1)\n",
    "\n",
    "wells_dedup = (\n",
    "    wells.sort_values([\"loc_key\", \"_ars_sort\", \"y\"], ascending=[True, False, False])\n",
    "         .drop_duplicates(\"loc_key\", keep=\"first\")\n",
    "         .drop(columns=[\"_ars_sort\"])\n",
    ")\n",
    "\n",
    "wells.shape, wells_dedup.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb651681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the minimal modeling table\n",
    "model_df = wells_dedup[[\n",
    "    \"DataID\",\n",
    "    \"xCoord\", \"yCoord\",\n",
    "    \"pH\",\n",
    "    \"depth_value\",\n",
    "    \"DepthType\",\n",
    "    \"GelogicUnit\",\n",
    "    \"ArsenicCat2\",\n",
    "    \"arsenic_value\",\n",
    "    \"y\",\n",
    "]].copy()\n",
    "\n",
    "model_df.rename(columns={\n",
    "    \"DataID\": \"well_id\",\n",
    "    \"xCoord\": \"longitude\",\n",
    "    \"yCoord\": \"latitude\",\n",
    "    \"pH\": \"ph\",\n",
    "    \"depth_value\": \"depth\",\n",
    "    \"DepthType\": \"depth_type\",\n",
    "    \"GelogicUnit\": \"geology_unit\",\n",
    "    \"ArsenicCat2\": \"EPA_threshold\",\n",
    "}, inplace=True)\n",
    "\n",
    "model_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5674c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class balance in the raw data without droping the missing rows\n",
    "wells[\"y\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f41e48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final data clean up - drop rows missing the predictors and target\n",
    "core = [\"well_id\", \"longitude\", \"latitude\", \"ph\", \"depth\", \"geology_unit\", \"EPA_threshold\", \"y\"]\n",
    "before = len(model_df)\n",
    "model_df_clean = model_df.dropna(subset=core).copy()\n",
    "model_df_clean[\"y\"].value_counts(dropna=False)\n",
    "after = len(model_df_clean)\n",
    "\n",
    "(before, after), model_df_clean[\"y\"].value_counts(dropna=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409b184b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = ROOT / \"data\" / \"processed\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "out_path = out_dir / \"model_table.csv\"\n",
    "model_df_clean.to_csv(out_path, index=False)\n",
    "\n",
    "out_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
